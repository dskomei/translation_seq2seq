{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorchチュートリアル　〜torxhtextのデータを使って翻訳モデルを作る〜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Tuple\n",
    "import math\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用するデータの取得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回使用するデータはtorchtextで用意されているものである。  \n",
    "そこで、torchtextに関して理解する。torchtextの解説は[このブログ](https://qiita.com/itok_msi/items/1f3746f7e89a19dafac5)を参考にしている。  \n",
    "\n",
    "Fieldクラスは読み込んだデータに施す前処理とその結果を管理するクラス  \n",
    "テキストをディープラーニングのモデルに取り込めるようにするためには、モデルが理解できるようにテキストを数値ベクトルに置き換えなければいけない。  \n",
    "そのためのプロセスは、定型的ではあるものの、各プロセスでやり方が色々あるため一見複雑に見える。そのため、その工程を管理する事ができれば楽に  \n",
    "必要なデータに変換できる。そのためのクラスである。  \n",
    "テキストを数値ベクトルに変換する工程は以下の通りである。（今回は文章を各単語に分割して単語を１単位とする学習データを想定している）  \n",
    "1. テキストを各単語に分割  \n",
    "1. 各単語に前処理を行う\n",
    "1. 各単語をインデックスに変換\n",
    "1. インデックスを数値ベクトルに変換\n",
    "\n",
    "　今回は文章を単語に分割するために「[https://spacy.io/](spaCy)」を使っている。これは自然言語処理を行うためのオープンソース・ソフトウェア・ライブラリである。  \n",
    "このライブラリはPyTorch以外にも、自然言語処理を扱う他のモジュール（TeonsorFlow, scikit-learn, Gensimなど）でも使うことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(\n",
    "    tokenize = \"spacy\",\n",
    "    tokenizer_language=\"de\",\n",
    "    init_token = '<sos>',\n",
    "    eos_token = '<eos>',\n",
    "    lower = True\n",
    ")\n",
    "\n",
    "TRG = Field(\n",
    "    tokenize = \"spacy\",\n",
    "    tokenizer_language=\"en\",\n",
    "    init_token = '<sos>',\n",
    "    eos_token = '<eos>',\n",
    "    lower = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts = ('.de', '.en'),\n",
    "    fields = (SRC, TRG)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi30kのデータは翻訳機械学習用のデータセットであり、指定した言語のデータを取得することができる。  \n",
    "上記では、ドイツ語と英語を指定し、fileds引数に上記で指定した文章を分割する関数を代入している。  \n",
    "このデータには主要なものとして「Filedsクラス」と「文章」が入っている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': <torchtext.data.field.Field at 0x11bdab588>,\n",
       " 'trg': <torchtext.data.field.Field at 0x11defe668>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.']\n",
      "['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']\n"
     ]
    }
   ],
   "source": [
    "examples = train_data.examples\n",
    "example = examples[0]\n",
    "src = example.src\n",
    "trg = example.trg\n",
    "print(src)\n",
    "print(trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('.', 4), ('ein', 5), ('einem', 6), ('in', 7), ('eine', 8), (',', 9)]\n",
      "[('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('a', 4), ('.', 5), ('in', 6), ('the', 7), ('on', 8), ('man', 9)]\n"
     ]
    }
   ],
   "source": [
    "src_tmp = list(train_data.fields['src'].vocab.stoi.items())[:10]\n",
    "trg_tmp = list(train_data.fields['trg'].vocab.stoi.items())[:10]\n",
    "\n",
    "print(src_tmp)\n",
    "print(trg_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単語をインデックス化し、固定長の長さに合わせ、指定したバッチサイズでミニバッチ化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  5,  18,   8,  ...,  54,   8,   5],\n",
      "        [ 13, 330, 113,  ...,  74,  36,  49],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  4,  16,   4,  ...,  19,   4,   4],\n",
      "        [  9, 326,  87,  ...,  17,  38, 348],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]])\n",
      "torch.Size([33, 128])\n"
     ]
    }
   ],
   "source": [
    "batch = iter(train_iterator).__next__()\n",
    "print(batch.src)\n",
    "print(batch.trg)\n",
    "print(batch.src.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 翻訳モデルの構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRUの定義はこのURLに記載してある。  \n",
    "https://pytorch.org/docs/stable/nn.html#gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            emb_dim, \n",
    "            enc_hid_dim, \n",
    "            bidirectional = True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "\n",
    "    def forward(self, src):\n",
    "\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "\n",
    "        outputs, hidden = self.rnn(embedded)\n",
    "\n",
    "        hidden = torch.tanh(self.fc(\n",
    "            torch.cat((\n",
    "                hidden[-2, :, :], \n",
    "                hidden[-1, :, :]), \n",
    "                dim = 1\n",
    "            )\n",
    "        ))\n",
    "\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim, attn_dim):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
    "\n",
    "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, decoder_hidden, encoder_outputs):\n",
    "\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "\n",
    "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(\n",
    "            1, \n",
    "            src_len, \n",
    "            1\n",
    "        )\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        energy = torch.tanh(self.attn(\n",
    "            torch.cat((\n",
    "                repeated_decoder_hidden,\n",
    "                encoder_outputs\n",
    "            ), dim = 2\n",
    "        )))\n",
    "\n",
    "        attention = torch.sum(energy, dim=2)\n",
    "\n",
    "        return F.softmax(attention, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            (enc_hid_dim * 2) + emb_dim, \n",
    "            dec_hid_dim\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def _weighted_encoder_rep(self, decoder_hidden, encoder_outputs):\n",
    "\n",
    "        a = self.attention(decoder_hidden, encoder_outputs)\n",
    "\n",
    "        a = a.unsqueeze(1)\n",
    "\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
    "\n",
    "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
    "\n",
    "        return weighted_encoder_rep\n",
    "\n",
    "\n",
    "    def forward(self, input, decoder_hidden, encoder_outputs):\n",
    "\n",
    "        input = input.unsqueeze(0)\n",
    "\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "\n",
    "        weighted_encoder_rep = self._weighted_encoder_rep(\n",
    "            decoder_hidden,\n",
    "            encoder_outputs\n",
    "        )\n",
    "\n",
    "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
    "\n",
    "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
    "\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
    "\n",
    "        output = self.out(\n",
    "            torch.cat((\n",
    "                output,\n",
    "                weighted_encoder_rep,\n",
    "                embedded\n",
    "            ), dim = 1)\n",
    "        )\n",
    "\n",
    "        return output, decoder_hidden.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        batch_size = src.shape[1]\n",
    "        max_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(\n",
    "            max_len, \n",
    "            batch_size, \n",
    "            trg_vocab_size\n",
    "        )\n",
    "\n",
    "        encoder_outputs, hidden = self.encoder(src)\n",
    "\n",
    "        # first input to the decoder is the <sos> token\n",
    "        output = trg[0,:]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "            output, hidden = self.decoder(\n",
    "                output, \n",
    "                hidden, \n",
    "                encoder_outputs\n",
    "            )\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.max(1)[1]\n",
    "            output = (trg[t] if teacher_force else top1)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルのパラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)     # 入力データの単語数\n",
    "OUTPUT_DIM = len(TRG.vocab)    # 出力データの単語数\n",
    "\n",
    "ENC_EMB_DIM = 32               # Encoder用のembeddingの次元数\n",
    "DEC_EMB_DIM = 32               # Decoder用のembeddingの次元数\n",
    "ENC_HID_DIM = 64               # Encoder用の隠れ層の次元数\n",
    "DEC_HID_DIM = 64               # Decoder用の隠れ層の次元数\n",
    "ATTN_DIM = 8                   # Attentionの隠れ層の次元数\n",
    "ENC_DROPOUT = 0.5              # Encoder用のDropout確率\n",
    "DEC_DROPOUT = 0.5              # Decoder用のDropout確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,856,685 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "enc = Encoder(\n",
    "    input_dim=INPUT_DIM, \n",
    "    emb_dim=ENC_EMB_DIM, \n",
    "    enc_hid_dim=ENC_HID_DIM, \n",
    "    dec_hid_dim=DEC_HID_DIM, \n",
    "    dropout=ENC_DROPOUT\n",
    ")\n",
    "\n",
    "attn = Attention(\n",
    "    enc_hid_dim=ENC_HID_DIM, \n",
    "    dec_hid_dim=DEC_HID_DIM, \n",
    "    attn_dim=ATTN_DIM\n",
    ")\n",
    "\n",
    "dec = Decoder(\n",
    "    output_dim=OUTPUT_DIM, \n",
    "    emb_dim=DEC_EMB_DIM, \n",
    "    enc_hid_dim=ENC_HID_DIM,\n",
    "    dec_hid_dim=DEC_HID_DIM, \n",
    "    dropout=DEC_DROPOUT, \n",
    "    attention=attn\n",
    ")\n",
    "\n",
    "model = Seq2Seq(\n",
    "    encoder=enc, \n",
    "    decoder=dec\n",
    ")\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "\n",
    "    # モデルを学習モードにする\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for _, batch in enumerate(iterator):\n",
    "\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(src, trg)\n",
    "\n",
    "        output = output[1:].view(-1, output.shape[-1])\n",
    "        trg = trg[1:].view(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    # 確認モードに切り替える（Dropoutを行わないなどの切り替え）\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg, 0) #turn off teacher forcing\n",
    "\n",
    "            output = output[1:].view(-1, output.shape[-1])\n",
    "            trg = trg[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    \n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 9m 8s\n",
      "\tTrain Loss: 4.668 | Train PPL: 106.505\n",
      "\t Val. Loss: 4.876 |  Val. PPL: 131.090\n",
      "Epoch: 02 | Time: 9m 41s\n",
      "\tTrain Loss: 4.476 | Train PPL:  87.914\n",
      "\t Val. Loss: 4.836 |  Val. PPL: 125.923\n",
      "Epoch: 03 | Time: 9m 25s\n",
      "\tTrain Loss: 4.371 | Train PPL:  79.153\n",
      "\t Val. Loss: 4.758 |  Val. PPL: 116.523\n",
      "Epoch: 04 | Time: 8m 51s\n",
      "\tTrain Loss: 4.267 | Train PPL:  71.339\n",
      "\t Val. Loss: 4.696 |  Val. PPL: 109.538\n",
      "Epoch: 05 | Time: 8m 58s\n",
      "\tTrain Loss: 4.160 | Train PPL:  64.052\n",
      "\t Val. Loss: 4.672 |  Val. PPL: 106.939\n",
      "Epoch: 06 | Time: 8m 56s\n",
      "\tTrain Loss: 4.060 | Train PPL:  57.958\n",
      "\t Val. Loss: 4.554 |  Val. PPL:  95.030\n",
      "Epoch: 07 | Time: 9m 0s\n",
      "\tTrain Loss: 3.966 | Train PPL:  52.797\n",
      "\t Val. Loss: 4.491 |  Val. PPL:  89.252\n",
      "Epoch: 08 | Time: 8m 57s\n",
      "\tTrain Loss: 3.893 | Train PPL:  49.052\n",
      "\t Val. Loss: 4.426 |  Val. PPL:  83.572\n",
      "Epoch: 09 | Time: 8m 59s\n",
      "\tTrain Loss: 3.806 | Train PPL:  44.966\n",
      "\t Val. Loss: 4.298 |  Val. PPL:  73.527\n",
      "Epoch: 10 | Time: 8m 59s\n",
      "\tTrain Loss: 3.723 | Train PPL:  41.380\n",
      "\t Val. Loss: 4.199 |  Val. PPL:  66.594\n",
      "Epoch: 11 | Time: 9m 0s\n",
      "\tTrain Loss: 3.651 | Train PPL:  38.509\n",
      "\t Val. Loss: 4.094 |  Val. PPL:  59.954\n",
      "Epoch: 12 | Time: 9m 6s\n",
      "\tTrain Loss: 3.565 | Train PPL:  35.341\n",
      "\t Val. Loss: 4.060 |  Val. PPL:  57.960\n",
      "Epoch: 13 | Time: 9m 1s\n",
      "\tTrain Loss: 3.492 | Train PPL:  32.852\n",
      "\t Val. Loss: 3.938 |  Val. PPL:  51.296\n",
      "Epoch: 14 | Time: 9m 9s\n",
      "\tTrain Loss: 3.414 | Train PPL:  30.396\n",
      "\t Val. Loss: 3.894 |  Val. PPL:  49.113\n",
      "Epoch: 15 | Time: 9m 3s\n",
      "\tTrain Loss: 3.362 | Train PPL:  28.839\n",
      "\t Val. Loss: 3.841 |  Val. PPL:  46.560\n",
      "Epoch: 16 | Time: 8m 58s\n",
      "\tTrain Loss: 3.306 | Train PPL:  27.280\n",
      "\t Val. Loss: 3.800 |  Val. PPL:  44.708\n",
      "Epoch: 17 | Time: 8m 57s\n",
      "\tTrain Loss: 3.264 | Train PPL:  26.159\n",
      "\t Val. Loss: 3.704 |  Val. PPL:  40.610\n",
      "Epoch: 18 | Time: 8m 57s\n",
      "\tTrain Loss: 3.193 | Train PPL:  24.353\n",
      "\t Val. Loss: 3.699 |  Val. PPL:  40.388\n",
      "Epoch: 19 | Time: 8m 54s\n",
      "\tTrain Loss: 3.146 | Train PPL:  23.235\n",
      "\t Val. Loss: 3.644 |  Val. PPL:  38.238\n",
      "Epoch: 20 | Time: 502m 15s\n",
      "\tTrain Loss: 3.079 | Train PPL:  21.747\n",
      "\t Val. Loss: 3.661 |  Val. PPL:  38.893\n",
      "Epoch: 21 | Time: 9m 1s\n",
      "\tTrain Loss: 3.055 | Train PPL:  21.211\n",
      "\t Val. Loss: 3.590 |  Val. PPL:  36.227\n",
      "Epoch: 22 | Time: 9m 43s\n",
      "\tTrain Loss: 3.022 | Train PPL:  20.533\n",
      "\t Val. Loss: 3.550 |  Val. PPL:  34.802\n",
      "Epoch: 23 | Time: 9m 28s\n",
      "\tTrain Loss: 2.985 | Train PPL:  19.782\n",
      "\t Val. Loss: 3.548 |  Val. PPL:  34.742\n",
      "Epoch: 24 | Time: 10m 18s\n",
      "\tTrain Loss: 2.943 | Train PPL:  18.967\n",
      "\t Val. Loss: 3.498 |  Val. PPL:  33.046\n",
      "Epoch: 25 | Time: 13m 19s\n",
      "\tTrain Loss: 2.888 | Train PPL:  17.960\n",
      "\t Val. Loss: 3.509 |  Val. PPL:  33.417\n",
      "Epoch: 26 | Time: 8m 52s\n",
      "\tTrain Loss: 2.884 | Train PPL:  17.890\n",
      "\t Val. Loss: 3.476 |  Val. PPL:  32.323\n",
      "Epoch: 27 | Time: 9m 40s\n",
      "\tTrain Loss: 2.852 | Train PPL:  17.319\n",
      "\t Val. Loss: 3.503 |  Val. PPL:  33.230\n",
      "Epoch: 28 | Time: 10m 36s\n",
      "\tTrain Loss: 2.821 | Train PPL:  16.788\n",
      "\t Val. Loss: 3.439 |  Val. PPL:  31.155\n",
      "Epoch: 29 | Time: 10m 10s\n",
      "\tTrain Loss: 2.778 | Train PPL:  16.095\n",
      "\t Val. Loss: 3.415 |  Val. PPL:  30.402\n",
      "Epoch: 30 | Time: 10m 10s\n",
      "\tTrain Loss: 2.764 | Train PPL:  15.867\n",
      "\t Val. Loss: 3.403 |  Val. PPL:  30.060\n",
      "| Test Loss: 3.423 | Test PPL:  30.646 |\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "CLIP = 1\n",
    "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(\n",
    "        model, \n",
    "        train_iterator, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        CLIP\n",
    "    )\n",
    "    \n",
    "    valid_loss = evaluate(\n",
    "        model, \n",
    "        valid_iterator, \n",
    "        criterion\n",
    "    )\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    \n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4.668191</td>\n",
       "      <td>4.875884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.476356</td>\n",
       "      <td>4.835670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.371384</td>\n",
       "      <td>4.758090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.267446</td>\n",
       "      <td>4.696274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4.159692</td>\n",
       "      <td>4.672259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>4.059719</td>\n",
       "      <td>4.554195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>3.966460</td>\n",
       "      <td>4.491463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3.892877</td>\n",
       "      <td>4.425706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3.805901</td>\n",
       "      <td>4.297657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>3.722802</td>\n",
       "      <td>4.198620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>3.650903</td>\n",
       "      <td>4.093570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>3.565032</td>\n",
       "      <td>4.059750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>3.492017</td>\n",
       "      <td>3.937618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>3.414327</td>\n",
       "      <td>3.894128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>3.361729</td>\n",
       "      <td>3.840732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>3.306162</td>\n",
       "      <td>3.800158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>3.264191</td>\n",
       "      <td>3.704007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>3.192656</td>\n",
       "      <td>3.698537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>3.145676</td>\n",
       "      <td>3.643834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>3.079472</td>\n",
       "      <td>3.660808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>3.054531</td>\n",
       "      <td>3.589798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>3.022037</td>\n",
       "      <td>3.549682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>2.984749</td>\n",
       "      <td>3.547959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>2.942711</td>\n",
       "      <td>3.497905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>2.888151</td>\n",
       "      <td>3.509068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>2.884228</td>\n",
       "      <td>3.475775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>2.851788</td>\n",
       "      <td>3.503464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>2.820677</td>\n",
       "      <td>3.438979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>2.778480</td>\n",
       "      <td>3.414524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>2.764263</td>\n",
       "      <td>3.403204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  train_loss  valid_loss\n",
       "0       1    4.668191    4.875884\n",
       "1       2    4.476356    4.835670\n",
       "2       3    4.371384    4.758090\n",
       "3       4    4.267446    4.696274\n",
       "4       5    4.159692    4.672259\n",
       "5       6    4.059719    4.554195\n",
       "6       7    3.966460    4.491463\n",
       "7       8    3.892877    4.425706\n",
       "8       9    3.805901    4.297657\n",
       "9      10    3.722802    4.198620\n",
       "10     11    3.650903    4.093570\n",
       "11     12    3.565032    4.059750\n",
       "12     13    3.492017    3.937618\n",
       "13     14    3.414327    3.894128\n",
       "14     15    3.361729    3.840732\n",
       "15     16    3.306162    3.800158\n",
       "16     17    3.264191    3.704007\n",
       "17     18    3.192656    3.698537\n",
       "18     19    3.145676    3.643834\n",
       "19     20    3.079472    3.660808\n",
       "20     21    3.054531    3.589798\n",
       "21     22    3.022037    3.549682\n",
       "22     23    2.984749    3.547959\n",
       "23     24    2.942711    3.497905\n",
       "24     25    2.888151    3.509068\n",
       "25     26    2.884228    3.475775\n",
       "26     27    2.851788    3.503464\n",
       "27     28    2.820677    3.438979\n",
       "28     29    2.778480    3.414524\n",
       "29     30    2.764263    3.403204"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({\n",
    "    'epoch' : np.arange(1, len(train_loss_list)+1),\n",
    "    'train_loss' : train_loss_list,\n",
    "    'valid_loss' : valid_loss_list\n",
    "})\n",
    "result.to_csv('model_result.csv', index=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
